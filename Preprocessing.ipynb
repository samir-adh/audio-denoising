{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time as Time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import (\n",
    "    generate_id,\n",
    "    preprocess_audio_file,\n",
    "    resample,\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"datasets/LibriSpeech\"):\n",
    "    !wget https://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "    !tar -xzf dev-clean.tar.gz\n",
    "    !mv LibriSpeech datasets/\n",
    "    !rm dev-clean.tar.gz\n",
    "if not os.path.exists(\"datasets/ESC-50-master\"):\n",
    "    !wget https://github.com/karoldvl/ESC-50/archive/master.zip\n",
    "    !unzip master.zip\n",
    "    !mv ESC-50-master datasets/\n",
    "    !rm master.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 2703 audio files in the dataset.\n",
      "400 noise files are selected.\n",
      "Preprocessing training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time : 2.261s.\n",
      "Preprocessing testing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time : 0.798s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script preprocesses audio files for the audio denoising project. It performs the following steps:\n",
    "1. Creates directories to store preprocessed files.\n",
    "2. Loads clean audio files from the LibriSpeech dataset.\n",
    "3. Loads noise audio files from the ESC-50 dataset and filters them to select only interior sounds.\n",
    "4. Resamples noise files to match the sample rate of the clean audio files.\n",
    "5. Preprocesses each clean audio file by adding noise and saves the resulting noisy audio files.\n",
    "\n",
    "Functions:\n",
    "- generate_id: Generates a unique identifier for a given audio signal.\n",
    "- preprocess_audio_file: Preprocesses a given audio file by adding noise and saves the clean and noisy versions.\n",
    "- resample: Resamples an audio signal to a specified sample rate.\n",
    "\n",
    "Constants:\n",
    "- CLEAN_DEV_DATASET: Path to the clean development dataset.\n",
    "- CLEAN_TRAIN_DATASET: Path to the clean training dataset.\n",
    "- MAX_CLEAN_AUDIOS: Maximum number of clean audio files to process.\n",
    "- NOISE_DATASET: Path to the noise dataset.\n",
    "- MAX_NOISE_SAMPLES: Maximum number of noise samples to use.\n",
    "\n",
    "Variables:\n",
    "- clean_ds_path: Path to the clean dataset.\n",
    "- clean_files_list: List of paths to clean audio files.\n",
    "- clean_samplerate: Sample rate of the clean audio files.\n",
    "- noise_files_list: List of paths to noise audio files.\n",
    "- sample_noise: Sample noise signal.\n",
    "- noise_samplerate: Sample rate of the noise audio files.\n",
    "- seed: Seed for random number generation.\n",
    "- random_state: Random state for shuffling the file lists.\n",
    "- n_noises: Number of noise files.\n",
    "- noises_array: Array of resampled noise signals.\n",
    "- noises_ids: List of unique identifiers for the noise signals.\n",
    "- start: Start time for preprocessing.\n",
    "- stop: Stop time for preprocessing.\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_files():\n",
    "    # Create directories to store preprocessed files\n",
    "    os.makedirs(\"preprocessed/train/clean_audio\", exist_ok=True)\n",
    "    os.makedirs(\"preprocessed/train/noisy_audio\", exist_ok=True)\n",
    "    os.makedirs(\"preprocessed/test/clean_audio\", exist_ok=True)\n",
    "    os.makedirs(\"preprocessed/test/noisy_audio\", exist_ok=True)\n",
    "    os.makedirs(\"preprocessed/temp\", exist_ok=True)\n",
    "\n",
    "    # Constants for dataset paths and limits\n",
    "    CLEAN_DEV_DATASET = \"datasets/LibriSpeech/dev-clean\"\n",
    "    CLEAN_TRAIN_DATASET = \"datasets/LibriSpeech/train-clean-100\"\n",
    "    MAX_CLEAN_AUDIOS = 16\n",
    "\n",
    "    # Load clean audio files from the dataset\n",
    "    clean_ds_path = CLEAN_DEV_DATASET\n",
    "    clean_files_list = []\n",
    "    for root, dirs, files in os.walk(clean_ds_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".flac\"):\n",
    "                fullpath = os.path.join(root, file)\n",
    "                clean_files_list.append(fullpath)\n",
    "    print(f\"There is a total of {len(clean_files_list)} audio files in the dataset.\")\n",
    "    _, clean_samplerate = soundfile.read(clean_files_list[0])\n",
    "\n",
    "    # Load noise audio files from the ESC-50 dataset and filter for interior sounds\n",
    "    NOISE_DATASET = \"datasets/ESC-50-master/\"\n",
    "    audio_dir = os.path.join(NOISE_DATASET, \"audio\")\n",
    "    labels_path = os.path.join(NOISE_DATASET, \"meta/esc50.csv\")\n",
    "    labels = pd.read_csv(labels_path)\n",
    "    MAX_NOISE_SAMPLES = 16\n",
    "\n",
    "    # Filter noise dataset to select only interior sounds\n",
    "    interior_noise_labels = labels[labels[\"target\"] // 10 == 3]\n",
    "    noise_files_list = [\n",
    "        os.path.join(audio_dir, row[\"filename\"])\n",
    "        for _, row in interior_noise_labels.iterrows()\n",
    "    ]\n",
    "    print(f\"{len(noise_files_list)} noise files are selected.\")\n",
    "    sample_noise, noise_samplerate = soundfile.read(noise_files_list[0])\n",
    "\n",
    "    # Shuffle the clean and noise file lists\n",
    "    seed = 123\n",
    "    random_state = np.random.RandomState(seed)\n",
    "    random_state.shuffle(clean_files_list)\n",
    "    random_state.shuffle(noise_files_list)\n",
    "\n",
    "    # Resample noise files to match the sample rate of clean audio files\n",
    "    n_noises = len(noise_files_list)\n",
    "    noises_array = np.zeros((n_noises, clean_samplerate))\n",
    "    noises_ids = []\n",
    "    for index in range(n_noises):\n",
    "        noise_file = noise_files_list[index]\n",
    "        noise_signal, _ = soundfile.read(noise_file)\n",
    "        cropped_noise = noise_signal[:noise_samplerate]\n",
    "        resampled_noise = resample(cropped_noise, noise_samplerate, clean_samplerate)\n",
    "        noises_array[index] = resampled_noise\n",
    "        noisy_audio_id = generate_id(noise_signal)\n",
    "        noises_ids.append(noisy_audio_id)\n",
    "\n",
    "    # Limit the number of clean and noise files to process\n",
    "    clean_files_list = clean_files_list[:MAX_CLEAN_AUDIOS]\n",
    "    noises_array = noises_array[:MAX_NOISE_SAMPLES]\n",
    "    noises_ids = noises_ids[:MAX_NOISE_SAMPLES]\n",
    "\n",
    "    training_clean_files = clean_files_list[:int(0.8 * len(clean_files_list))]\n",
    "    testing_clean_files = clean_files_list[int(0.8 * len(clean_files_list)):]\n",
    "\n",
    "    # Preprocess each clean audio file by adding noise and save the results\n",
    "    print(\"Preprocessing training data...\")\n",
    "    start = Time.time()\n",
    "    for index in tqdm(range(len(training_clean_files))):\n",
    "        audio_file = training_clean_files[index]\n",
    "        preprocess_audio_file(\n",
    "            audio_file=audio_file,\n",
    "            clean_path=\"preprocessed/train/clean_audio\",\n",
    "            noisy_path=\"preprocessed/train/noisy_audio\",\n",
    "            clean_samplerate=clean_samplerate,\n",
    "            noises_array=noises_array,\n",
    "            noises_ids=noises_ids,\n",
    "            max_segments=2\n",
    "        )\n",
    "    stop = Time.time()\n",
    "    print(f\"Total time : {stop-start:.3f}s.\")\n",
    "\n",
    "    print(\"Preprocessing testing data...\")\n",
    "    start = Time.time()\n",
    "    for index in tqdm(range(len(testing_clean_files))):\n",
    "        audio_file = testing_clean_files[index]\n",
    "        preprocess_audio_file(\n",
    "            audio_file=audio_file,\n",
    "            clean_path=\"preprocessed/test/clean_audio\",\n",
    "            noisy_path=\"preprocessed/test/noisy_audio\",\n",
    "            clean_samplerate=clean_samplerate,\n",
    "            noises_array=noises_array,\n",
    "            noises_ids=noises_ids,\n",
    "            max_segments=2\n",
    "        )\n",
    "    stop = Time.time()\n",
    "    print(f\"Total time : {stop-start:.3f}s.\")\n",
    "\n",
    "if not os.path.exists(\"preprocessed/train/clean_audio\") or not os.path.exists(\"preprocessed/test/clean_audio\"):\n",
    "    preprocess_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
